
<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Manideep Elasagaram Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>Manideep Elasagaram Portfolio<br />
						</h1>
						<a href="https://github.com/manideepelasagaram" class="image main"><img src="images/IMG_7613.jpeg" alt="" /></a>
						<ul class="actions special"></ul>
						<p>a Data Analyst with over three years of experience in healthcare and operational analytics. I hold a Master's degree in Business Analytics from California State University, East Bay, and specialize in turning complex data into actionable insights.

							At Duke Health Technology Solutions and Northern California SBDC, I developed data solutions using Python, SQL, and Râ€”optimizing EHR workflows, automating ETL pipelines, and building dashboards in Power BI and Tableau. I've also delivered machine learning models using tools like Scikit-learn, XGBoost, and PyTorch.
							
							With hands-on experience in big data technologies such as Hadoop, Spark, and Hive, and cloud platforms like AWS and Azure, I bring a well-rounded, impact-driven approach to analytics and decision support.
							<!-- <a href="https://www.linkedin.com/in/manideep-elasagaram/">@manideepelasagaram</a> -->
						
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
							
						</ul>
					</div>

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Manideep Elasagaram</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Projects</a></li>
							
						</ul>
						<ul class="icons">
							<li><a href="https://public.tableau.com/app/profile/manideep.elasagaram/vizzes" class="icon brands alt fa-tableau"><span class="label">Tableau</span></a></li>
							<li><a href="https://github.com/manideepelasagaram" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Featured Post -->
							<article class="post featured">
								<header class="major">
									
									<h2><a href="https://github.com/manideepelasagaram/Electric-Vehicle-Purchase-Prediction-Data-Preprocessing-Model-Training-and-Prediction">
										Electric Vehicle Purchase Prediction: Data Preprocessing Model Training and Prediction<br />
									</a></h2>
									<p>This project showcases a robust approach to data preprocessing and classification for a given dataset, starting with comprehensive data exploration to identify duplicates, missing values, and outliers. Categorical features are analyzed and encoded, while new features are engineered, such as geographical encodings. The project meticulously examines numerical feature skewness, outliers, and correlations, employing feature selection techniques like Recursive Feature Elimination and independence tests to refine the feature set.

										Two classification models, Random Forest Classifier and XGBoost Classifier, are trained and rigorously evaluated, with the XGBoost model being chosen for its superior performance. The final model is utilized to make predictions on a test dataset, and the results are saved in a CSV file. This project exemplifies the entire machine learning pipeline, from data preprocessing and feature engineering to model training and evaluation, demonstrating a comprehensive and methodical approach to developing effective machine learning solutions.</p>
								</header>
								<a href="https://github.com/manideepelasagaram/Electric-Vehicle-Purchase-Prediction-Data-Preprocessing-Model-Training-and-Prediction" class="image main"><img src="images/Electric car.webp" alt="" /></a>
								<ul class="actions special">
									<li><a href="https://github.com/manideepelasagaram/Electric-Vehicle-Purchase-Prediction-Data-Preprocessing-Model-Training-and-Prediction" class="button large">View Project</a></li>
								</ul>
							</article>

						<!-- Posts -->
							<section class="posts">
								<article>
									<header>
										
										<h2><a href="https://github.com/manideepelasagaram/Database-Management-System">
											Database Management of Netflix<br />
										</a></h2>
									</header>
									<a href="https://github.com/manideepelasagaram/Database-Management-System" class="image fit"><img src="images/Netflix.png" alt="" /></a>
									<p>The "Database Management of Netflix" project involved creating comprehensive relational, dimensional, and entity-relationship (E-R) data models to effectively store and manage customer and content data. Aimed at analyzing customer subscription behavior, the project provided insights to help Netflix make informed business decisions and personalized recommendations. It included implementing Data Definition Language (DDL) and Data Manipulation Language (DML) to establish and maintain the database structure, ensuring data accuracy through constraints and triggers. Additionally, complex queries were executed to retrieve, update, and manipulate data based on business requirements, such as identifying popular content and understanding peak usage times. This project emphasized both the technical aspects of database management and the strategic use of data to drive business growth and enhance customer satisfaction for Netflix.</p>
									<ul class="actions special">
										<li><a href="https://github.com/manideepelasagaram/Database-Management-System" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h2><a href="https://github.com/manideepelasagaram/Visibility-Analysis-using-Apache-Spark-">Visibility Analysis using Apache Spark<br />
										</a></h2>
									</header>
									<a href="https://github.com/manideepelasagaram/Visibility-Analysis-using-Apache-Spark-" class="image fit"><img src="images/Visibility .jpeg" alt="" /></a>
									<p>
										The Visibility Analysis using Apache Spark project is an extensive data processing and analysis initiative that leverages advanced Big Data technologies like Hadoop, PySpark, Pig, and Hive. It is organized into four distinct tasks, each fulfilling specific analytical requirements. The first task develops Mapper and Reducer applications to determine sky ceiling height ranges for each observation month. The second task utilizes a PySpark application to compute the average visibility distance for each USAF weather station ID. The third task focuses on Pig, loading and processing a text file to extract sky ceiling height ranges for each USAF weather station ID. The final task employs Hive to load a text file and calculate the average sky ceiling height for each USAF weather station ID. Users are guided on configuring PySpark correctly, preprocessing NCDC records, and placing them in the appropriate input directories. The execution involves running designated scripts for each task, emphasizing the correct configuration of SparkContext and file paths to ensure seamless operation.</p>
									<ul class="actions special">
										<li><a href="https://github.com/manideepelasagaram/Visibility-Analysis-using-Apache-Spark-" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h2><a href="https://github.com/manideepelasagaram/Multi-class-Obesity-Risk-Prediction-">
											Multi Class Obesity Risk Prediction<br />
										</a></h2>
									</header>
									<a href="https://github.com/manideepelasagaram/Multi-class-Obesity-Risk-Prediction-" class="image fit"><img src="images/Obesity Risk.webp" alt="" /></a>
									<p>
										In this project, we aimed to predict obesity risk using machine learning algorithms on a dataset containing demographic details, lifestyle habits, and physical characteristics. Following data exploration and preprocessing, which included one-hot encoding for categorical variables and splitting the data into training and validation sets, we applied various models such as Random Forest, Decision Tree, MLP, and Gradient Boosting Classifiers. The Gradient Boosting Classifier emerged as the best performer, achieving an impressive accuracy of 90%. Our results demonstrate that leveraging machine learning can facilitate early intervention and preventive healthcare strategies to reduce obesity risks, highlighting the importance of data-driven approaches in healthcare decision-making.
										
										
										
										
										
										
										</p>
									<ul class="actions special">
										<li><a href="https://github.com/manideepelasagaram/Multi-class-Obesity-Risk-Prediction-" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h2><a href="https://github.com/manideepelasagaram/Forecasting-Air-Passengers-using-R-and-the-Forecast-Library">
											Forecasting Air Passengers using R and the Forecast Library<br />
										</a></h2>
									</header>
									<a href="https://github.com/manideepelasagaram/Forecasting-Air-Passengers-using-R-and-the-Forecast-Library" class="image fit"><img src="images/Air Passengers.jpeg" alt="" /></a>
									<p>This script meticulously guides through time series analysis, starting with transforming monthly air passenger data into a structured time series object. Employing exploratory data analysis techniques, it reveals trends and seasonal patterns, preparing for model fitting. The script applies an autoregressive integrated moving average (ARIMA) model, specifically AR(1), to capture and analyze data autocorrelation for predictability. Model diagnostics, including hypothesis testing and autocorrelation analysis, deepen the understanding of data behavior. By partitioning the time series into training and validation sets, it enhances predictive accuracy, culminating in the forecasting phase. With strong models and historical insights, the script forecasts future air passenger volumes using various techniques. Rigorous validation with metrics like mean absolute error (MAE) and root mean squared error (RMSE) ensures robustness and precision, facilitating informed decisions and accurate future projections of air passenger volumes.</p>
									<ul class="actions special">
										<li><a href="https://github.com/manideepelasagaram/Forecasting-Air-Passengers-using-R-and-the-Forecast-Library" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h2><a href="https://github.com/manideepelasagaram/Real-Estate-of-Bay-Area">Real Estate of Bay Area, Web Scraping and Analysis<br />
										</a></h2>
									</header>
									<a href="https://github.com/manideepelasagaram/Real-Estate-of-Bay-Area" class="image fit"><img src="images/Real Estate.jpeg" alt="" /></a>
									<p>In this data analytics project targeting the California Bay Area real estate market, we collected and cleaned 2,500 rows of housing data from Redfin, featuring 30 different attributes. Through rigorous data cleansing and exploratory data analysis (EDA), we developed a machine learning model using XGBoost to predict house prices with high accuracy, achieving an R-squared (R2) value of 0.98. Our analysis offers valuable insights into market trends and key price predictors, equipping stakeholders with actionable information for strategic decision-making in the dynamic California Bay Area real estate market.</p>
									<ul class="actions special">
										<li><a href="https://github.com/manideepelasagaram/Real-Estate-of-Bay-Area" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h2><a href="https://github.com/manideepelasagaram/Automated-ETL-Pipeline-for-Banking-Data-Analysis">
											Automated ETL Pipeline for Banking Data Analysis<br />
										</a></h2>
									</header>
									<a href="https://github.com/manideepelasagaram/Automated-ETL-Pipeline-for-Banking-Data-Analysis" class="image fit"><img src="images/ETL.jpeg" alt="" /></a>
									<p>The Automated ETL Pipeline for Banking Data Analysis project aimed to streamline the extraction, transformation, and loading (ETL) process for banking data, facilitating efficient analysis and decision-making. We automated the retrieval and processing of diverse banking data, handling various formats and cleaning inconsistencies to prepare the data for analysis. Using advanced techniques like web scraping, we extracted relevant information from web sources, ensuring comprehensive data coverage. The pipeline included robust transformation steps, such as currency conversion based on exchange rates, to standardize data across multiple currencies. We employed state-of-the-art machine learning models for predictive analytics, gaining insights into market capitalization trends and financial performance. Our results demonstrated the power of automation in banking data analysis, enhancing efficiency and accuracy in decision-making processes. By leveraging data-driven approaches, we obtained valuable insights into market dynamics, regulatory compliance, and risk management. This project highlights the transformative impact of automated ETL pipelines in the banking sector, emphasizing the importance of advanced technologies for optimizing data workflows and driving organizational success in the financial industry. Skills: Web Scraping, Python, Extract, Transform, Load (ETL), Pipelines, Data Analysis.</p>
									<ul class="actions special">
										<li><a href="https://github.com/manideepelasagaram/Automated-ETL-Pipeline-for-Banking-Data-Analysis" class="button">View Project</a></li>
									</ul>
								</article>
							</section>

					
						<section class="split contact">
							<section class="alt">
								<h3>Location:</h3>
								<p>The Triangle,<br />
								Morrisville, NC, 27560<br />
								United States.</p>
							</section>
							<section>
								<h3>Phone:</h3>
								<p><a href="#">+1(925)-789-8511</a></p>
							</section>
							<section>
								<h3>Email:</h3>
								<p><a href="#">melasagaram@horizon.csueastbay.edu</a></p>
							</section>
							<section>
								<h3>Social:</h3>
								<ul class="icons alt">
									<li><a href="https://public.tableau.com/app/profile/manideep.elasagaram/vizzes" class="icon brands alt fa-tableau"><span class="label">tableau</span></a></li>
									<li><a href="https://github.com/manideepelasagaram" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>

								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
